MODEL:
  META_ARCHITECTURE: "IDOL"
  WEIGHTS: "cocopretrain_R101.pth" # "cocopretrain_R101.pth" #"YTVIS21_R101_485AP.pth" r101_2f_semi_cont
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_ON: True
  RESNETS:
    DEPTH: 101
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  #CLS_TH: 0.8
  #MASK_TH: 0.8
  #cascade or independent, future implmentation strategies like DPA, flexmatch, mask-base box refinement....
  #TH_TYPE: ("cascade")
  
  IDOL:
    NUM_CLASSES: 40
    MULTI_CLS_ON: True
DATASETS:
  TRAIN: ("ytvis_2021_train",)
  #TRAIN_UNLABELED: ("ytvis_2021_train_unlabeled",)
  TEST: ("ytvis_2021_val",)
SOLVER:
  IMS_PER_BATCH: 1 #32
  BASE_LR: 0.0001
  STEPS: (8000,)
  MAX_ITER: 12000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  CHECKPOINT_PERIOD: 1000
INPUT:
  SAMPLING_FRAME_NUM: 2
  SAMPLING_FRAME_RANGE:  10
  # MIN_SIZE_TRAIN_SAMPLING : ["range", "choice", "range_by_clip", "choice_by_clip"]
  MIN_SIZE_TRAIN_SAMPLING: "choice_by_clip"
  # RANDOM_FLIP : ["none", "horizontal", "flip_by_clip"]. "horizontal" is set by default.
  RANDOM_FLIP: "flip_by_clip"
  # AUGMENTATIONS: []
  # MIN_SIZE_TRAIN: (360, 480)
  MIN_SIZE_TRAIN: (320, 352, 392, 416, 448, 480, 512, 544, 576, 608, 640)
  MAX_SIZE_TRAIN: 768
  MIN_SIZE_TEST: 480
  CROP:
    ENABLED: True
    TYPE: "relative_range"
    SIZE: (0.9, 0.9)
  FORMAT: "RGB"
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: False
  NUM_WORKERS: 8
VERSION: 2
SEMI: False
CLF_TH: 1.
MASK_TH: 0.5
DPA: True
OUTPUT_DIR: ./YTVIS21_R101_2f_no_OT
